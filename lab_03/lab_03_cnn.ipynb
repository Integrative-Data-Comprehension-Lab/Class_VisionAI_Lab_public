{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural Network\n",
    "============================\n",
    "\n",
    "이번 실습에서는 지난 시간에 작성한 코드의 사용성을 더 개선하고 간단한 CNN모델을 구현해본다.\n",
    "1. custom datasets 작성하기\n",
    "2. W&B를 이용하여 학습및 평가 트래킹하기\n",
    "3. CNN모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom datasets 작성하기\n",
    "``torch.utils.data.Dataset``는 dataset을 위한 추상클래스이다. custom dataset은 이 클래스를 상속하고 아래 두가지 메서드를 override하여야 한다:\n",
    "\n",
    "\n",
    "\n",
    "* `__len__`을 구현하여 len(dataset)이 데이터셋 크기를 리턴한다\n",
    "\n",
    "* `__getitem__` 을 구현하여 dataset[i] 와 같은 인덱싱에서 i번째 샘플을 리턴한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetExample(Dataset):\n",
    "    def __init__ (self , X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        assert len(X) == len(y)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "data_x = torch.rand([10, 3], dtype=torch.float32) #example tensor dataset with 3 feature and 10 examples\n",
    "data_y = torch.arange(10) # target y\n",
    "\n",
    "example_dataset = CustomDatasetExample(data_x, data_y)\n",
    "print(f\"Dataset 크기: {len(example_dataset)}\")\n",
    "print(f\"4-th example: {example_dataset[3]}\\n\")\n",
    "for X, y in example_dataset:\n",
    "    print(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 아래 csv파일로 부터 이미지 경로와 라벨 정보를 읽어오는 사용자정의 dataset을 구현해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "pd.read_csv('resources/cat_dog_images/meta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>과제</mark>: root directory의 경로 \"resources/cat_dog_images\"와 이미지의 경로 및 label를 저장하고 있는 메타데이터 meta.csv파일을 입력으로 받는 custom datsets을 구현하라\n",
    "\n",
    "* 이미지를 읽는데에는 [PIL.Image.open](https://pillow.readthedocs.io/en/stable/reference/Image.html) 함수를 사용할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, metadata_filename, transform=None, target_transform=None):\n",
    "        self.metadata_df = pd.read_csv(os.path.join(root_dir, metadata_filename))\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "        classes = self.metadata_df[\"label\"].drop_duplicates().sort_values().tolist()\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        ##### YOUR CODE START #####  \n",
    "        \n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ##### YOUR CODE START #####  \n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "        label = self.class_to_idx[label_str] # encode label to integer\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "custom_dataset = CustomImageDataset(root_dir = 'resources/cat_dog_images', \n",
    "                                   metadata_filename = \"meta.csv\",\n",
    "                                   transform = transform)\n",
    "\n",
    "for i in range(len(custom_dataset)):\n",
    "    image, target = custom_dataset[i]\n",
    "    print(f\"{i+1}-th example: X.shape = {image.shape}, label = {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataset, cols=8, rows=5):\n",
    "    figure = plt.figure(figsize=(12, 6))\n",
    "    for i in range(len(dataset)):\n",
    "        img, label = dataset[i]\n",
    "        figure.add_subplot(rows, cols, i+1)\n",
    "        plt.title(label)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(img.numpy().transpose((1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "visualize_samples(custom_dataset, rows = 2 , cols = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 모든 샘플의 이미지 크기가 같지 않기 때문에 아래와 같이 dataloader를 이용해 mini-batch로 쌓으려고 하면 오류가 생긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset= custom_dataset, batch_size=6, shuffle=True)\n",
    "for X, y in train_dataloader:\n",
    "    print(X.shape, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 transforms를 이용한 전처리가 필요하다.\n",
    "``torchvision.transforms``에 다양한 이미지 전처리 함수가 이미 구현되어있다. 자세히는 [documentation](https://pytorch.org/vision/main/transforms.html)을 참고하기 바란다. \n",
    "\n",
    "여기서는 그 중 자주 사용되는 몇 가지를 소개한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "custom_datset_train = CustomImageDataset(root_dir = 'resources/cat_dog_images', \n",
    "                                   metadata_filename = \"meta.csv\",\n",
    "                                   transform = train_transform)\n",
    "\n",
    "visualize_samples(custom_datset_train, rows = 2 , cols = 3)\n",
    "visualize_samples(custom_datset_train, rows = 2 , cols = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 뽑을때 마다 랜덤하게 다른 augmented image가 출력되는것을 확인할 수 있다.\n",
    "데이터로더에서도 (3, 224, 224) 크기의 이미지가 잘 출력됨을 확인할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset= custom_datset_train, batch_size=6, shuffle=True)\n",
    "for X, y in train_dataloader:\n",
    "    print(X.shape, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom Sampler로 weighted sampling하기\n",
    "\n",
    "Sampler는 dataloader가 data를 추출하는 순서를 정해주는 객체로 datasets의 index를 순차적으로 리턴하는 iterator이다.\n",
    "\n",
    "``__iter__``에서는 데이터셋의 순서를 정하는 로직을 통과한 뒤 그 인덱스들을 순회할수 있는 iterator를 반환한다.\n",
    "\n",
    "아래 예시는 label imbalance를 해결하기 위해 각 class로 부터 같은 숫자의 샘플들을 추출하는 샘플러이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "import random\n",
    "\n",
    "class BalancedSampler(Sampler): \n",
    "    def __init__(self, dataset, class_column_name='label'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset: The dataset to sample from.\n",
    "            class_column_name: The column name in the dataset that contains class labels.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.class_column_name = class_column_name\n",
    "        \n",
    "        # Group indices by class\n",
    "        self.class_indices = {}\n",
    "        for idx, label in enumerate(self.dataset.metadata_df[class_column_name]):\n",
    "            if label not in self.class_indices:\n",
    "                self.class_indices[label] = []\n",
    "            self.class_indices[label].append(idx)\n",
    "        \n",
    "        self.min_class_length = min(len(indices) for indices in self.class_indices.values())\n",
    "        \n",
    "    def __iter__(self):\n",
    "        selected_indices = []\n",
    "\n",
    "        for class_name, indices in self.class_indices.items():\n",
    "            sampled_indices = random.sample(indices, self.min_class_length)\n",
    "            selected_indices.extend(sampled_indices)\n",
    "        \n",
    "        random.shuffle(selected_indices)\n",
    "        return iter(selected_indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # The length of the sampler will be twice the minimum class length since we are balancing\n",
    "        return self.min_class_length * len(self.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "custom_datset_imbalance = CustomImageDataset(root_dir = 'resources/cat_dog_images', \n",
    "                                   metadata_filename = \"meta_imbalanced.csv\",\n",
    "                                   transform = train_transform)\n",
    "\n",
    "print(f\"this dataset has imbalanced label :{[custom_datset_imbalance[i][1] for i in range(len(custom_datset_imbalance))]}\\n\")\n",
    "\n",
    "balanced_sampler = BalancedSampler(custom_datset_imbalance)\n",
    "print(f\"class to dataset index dict: {balanced_sampler.class_indices}\")\n",
    "print(f\"sampled index : {[idx for idx in balanced_sampler]}\\n\")\n",
    "\n",
    "dataloader = DataLoader(custom_datset_imbalance, batch_size=32, sampler=balanced_sampler)\n",
    "for X, y in dataloader:\n",
    "    print(f\"mini-batch X.shape = {X.shape}, target y = {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 코드 개선하기\n",
    "\n",
    "아래는 지난 실습에서 작성한 학습코드를 다음의 측면에서 개선한 코드이다. 코드를 리뷰하며 다시 복습해보자.\n",
    "\n",
    "- tqdm을 이용학 학습 시간 추적\n",
    "- AverageMeter를 사용하여 학습 metric을 추적\n",
    "- save_checkpoint와 load_checkpoint를 이용하여 모델을 저장하고 불러오는 기능 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_MNIST_datasets(data_root_dir):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.MNIST(\n",
    "        root=data_root_dir, train=True, download=True, \n",
    "        transform=transform\n",
    "    )\n",
    "    test_dataset = datasets.MNIST(\n",
    "        root=data_root_dir, train=False, download=True, \n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_dataset, test_dataset, device, batch_size, num_worker):\n",
    "    kwargs = {}\n",
    "    if device.startswith(\"cuda\"):\n",
    "        kwargs.update({\n",
    "            'pin_memory': True,\n",
    "        })\n",
    "\n",
    "    train_dataloader = DataLoader(dataset = train_dataset, batch_size=batch_size, \n",
    "                                  shuffle=True, num_workers=num_worker, **kwargs)\n",
    "    test_dataloader = DataLoader(dataset = test_dataset, batch_size=batch_size, \n",
    "                                 shuffle=False, num_workers=num_worker, **kwargs)\n",
    "    \n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name}: {avg' + self.fmt + '} (n={count}))'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "def calculate_accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "    \n",
    "def save_checkpoint(filepath, model, optimizer, epoch, best_acc1, is_best, best_model_path):\n",
    "    save_dir = os.path.split(filepath)[0]\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    state = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch + 1,\n",
    "        'best_acc1': best_acc1,\n",
    "    }\n",
    "    \n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, best_model_path)\n",
    "\n",
    "\n",
    "def load_checkpoint(filepath, model, optimizer, device):\n",
    "    if os.path.isfile(filepath):\n",
    "        checkpoint = torch.load(filepath, map_location=device)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_acc1 = checkpoint['best_acc1']\n",
    "        print(f\"=> loaded checkpoint '{filepath}' (epoch {start_epoch})\")\n",
    "        return start_epoch, best_acc1\n",
    "    else:\n",
    "        print(f\"=> no checkpoint found at '{filepath}'\")\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, device, dataloader, criterion, optimizer, epoch):\n",
    "    # train for one epoch\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    acc_top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    data_time = AverageMeter('Data_Time', ':6.3f') # Time for data loading\n",
    "    batch_time = AverageMeter('Batch_Time', ':6.3f') # time for mini-batch train\n",
    "    metrics_list = [losses, acc_top1, data_time, batch_time, ]\n",
    "    \n",
    "    model.train() # switch to train mode\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    tqdm_epoch = tqdm(dataloader, desc=f'Training Epoch {epoch + 1}', total=len(dataloader))\n",
    "    for images, target in tqdm_epoch:\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        acc1, = calculate_accuracy(output, target, topk=(1,))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        acc_top1.update(acc1[0], images.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "\n",
    "        tqdm_epoch.set_postfix(avg_metrics = \", \".join([str(x) for x in metrics_list]))\n",
    "\n",
    "        end = time.time()\n",
    "    tqdm_epoch.close()\n",
    "\n",
    "    ##### YOUR CODE START #####\n",
    "    # wandb log following variables: losses.avg, acc_top1.avg\n",
    "\n",
    "    ##### YOUR CODE END #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_loop(model, device, dataloader, criterion, epoch = 0):\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    acc_top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    metrics_list = [losses, acc_top1]\n",
    "\n",
    "    model.eval() # switch to evaluate mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tqdm_val = tqdm(dataloader, desc='Validation/Test', total=len(dataloader))\n",
    "        for images, target in tqdm_val:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            acc1, = calculate_accuracy(output, target, topk=(1,))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            acc_top1.update(acc1[0], images.size(0))\n",
    "\n",
    "            tqdm_val.set_postfix(avg_metrics = \", \".join([str(x) for x in metrics_list]))\n",
    "\n",
    "        tqdm_val.close()\n",
    "\n",
    "    ##### YOUR CODE START #####\n",
    "\n",
    "    ##### YOUR CODE END #####\n",
    "\n",
    "    return acc_top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_main_MLP():\n",
    "    ## data and preprocessing settings\n",
    "    data_root_dir = '/datasets' \n",
    "    num_worker = 4\n",
    "\n",
    "    ## Hyper parameters\n",
    "    batch_size = 128\n",
    "    learning_rate = 1e-3\n",
    "    start_epoch = 0\n",
    "    num_epochs = 50\n",
    "\n",
    "    ## checkpoint setting\n",
    "    checkpoint_save_interval = 10\n",
    "    checkpoint_path = \"checkpoints/checkpoint.pth\"\n",
    "    best_model_path = \"checkpoints/best_model.pth\"\n",
    "    load_from_checkpoint = None # Options: \"latest\", \"best\", or None\n",
    "\n",
    "    ## variables\n",
    "    best_acc1 = 0\n",
    "\n",
    "    ## set learning deterministic\n",
    "    # torch.manual_seed(1)\n",
    "\n",
    "    ##### YOUR CODE START #####\n",
    "\n",
    "    ##### YOUR CODE END #####\n",
    "\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(f\"Using {device} device\")\n",
    "\n",
    "    train_dataset, test_dataset = load_MNIST_datasets(data_root_dir)\n",
    "    num_classes = len(train_dataset.classes)\n",
    "    \n",
    "    train_dataloader, test_dataloader = create_dataloaders(train_dataset, test_dataset, device, \n",
    "                                                           batch_size = batch_size, num_worker = num_worker)\n",
    "\n",
    "\n",
    "    model = MultiLayerPerceptron(in_dim = 28*28, hidden_dim = 512, out_dim = num_classes).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    if load_from_checkpoint:\n",
    "        load_checkpoint_path = (best_model_path if load_from_checkpoint == \"best\" else checkpoint_path)\n",
    "        start_epoch, best_acc1 = load_checkpoint(load_checkpoint_path, model, optimizer, device)\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        train_loop(model, device, train_dataloader, criterion, optimizer, epoch)\n",
    "        acc1 = evaluation_loop(model, device, test_dataloader,criterion, epoch)\n",
    "\n",
    "\n",
    "        is_best = acc1 > best_acc1\n",
    "        best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "        if (epoch + 1) % checkpoint_save_interval == 0 or is_best:\n",
    "            save_checkpoint(checkpoint_path, model, optimizer, epoch, best_acc1, is_best, best_model_path)\n",
    "\n",
    "    ##### YOUR CODE START #####\n",
    "\n",
    "    ##### YOUR CODE END #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>과제</mark> [wandb](https://kr.wandb.ai/) 회원가입을 하고 메뉴얼에 따라 Train Loss, Train Accuracy, Validation Loss, Validation Accuracy를 추적하도록 위 함수들을 적절히 수정하고 학습해보라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "train_main_MLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>과제</mark> wandb 로그 폴더와 checkpoint를 git에 올리지 않기 위에 `.gitignore`를 수정하라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(참고) shell 환경변수를 설정하여 wandb를 끌수있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "train_main_MLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a small Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN은 보통 아래 4개 레이어로 구성된다\n",
    "\n",
    "- Convolutional layer\n",
    "- Activation \n",
    "- Pooling layer\n",
    "- FC layer\n",
    "\n",
    "PyTorch에는 다양한 레이어가 있지만 우리는 그중 Conv2d, ReLU, Maxpool, Linear(FC) 레이어를 이용할 예정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Conv2d\n",
    "\n",
    "parameter\n",
    "\n",
    "- in_channels(int) : Number of input images channel\n",
    "- out_channels(int) : Number of filters\n",
    "- kernel_size(int or tuple) : 필터의 크기는 kernel_size * kernel_size이다\n",
    "- stride(int or tuple) : Default = 1\n",
    "- padding(int or tuple) : zero padding. Default = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "input_image = torch.rand(16, 1, 28, 28) # dummy data with batch_size 16\n",
    "conv_layer1 = nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = 5)\n",
    "x = conv_layer1(input_image)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.MaxPool2d\n",
    "\n",
    "parameter\n",
    "- kernel_size – the size of the window to take a max over\n",
    "- stride – the stride of the window. (Default = kernel_size)\n",
    "- padding – implicit zero padding to be added on both sides (default = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "pool_layer = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "x = pool_layer(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 CNN 모델을 구현할 준비가 완료되었다.\n",
    "\n",
    "<mark>과제</mark> 아래 구조의 CNN모델을 완성하라\n",
    "\n",
    "* 5x5 Convolutional layer with 8 filters, strides of 1, no zero padding, and ReLU activation\n",
    "* 2x2 Max pooling layer with strides of 2\n",
    "* 5x5 Convolutional layer with 16 filters, strides of 1, no zero padding, and ReLU activation\n",
    "* 2x2 Max pooling layer with strides of 2\n",
    "* Fully connected layer with 128 output units and ReLU activation\n",
    "* Fully connected layer with 64 output units and ReLU activation\n",
    "* Fully connected layer with 10 output units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "    def forward(self, x):\n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파라미터 수를 스스로 계산해보고 맞게 구현됐는지 검증하라\n",
    "\n",
    "- Conv layer = filter number x filter size x filter size + bias(filter number)\n",
    "- FC layer = input size x output size + bias(output size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "cnn_model = SimpleCNN()\n",
    "for name, param in cnn_model.named_parameters():\n",
    "    print(f\"Layer {name} # of params : {param.numel()}\")\n",
    "total_params = sum(p.numel() for p in cnn_model.parameters())\n",
    "\n",
    "print(f\"Total number of params : {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>과제</mark> 학습을 수행하여 MLP 모델과의 결과를 비교하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_main_CNN():\n",
    "    ##### YOUR CODE START #####\n",
    "\n",
    "    ##### YOUR CODE END #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "train_main_MLP()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
